# Local LLM (Ollama) â€” used by default for job-description tailoring
# Ensure Ollama is running (e.g. ollama serve) and pull a model: ollama pull llama3.2
RESUME_LLM_MODEL=llama3.2
# OLLAMA_HOST=http://localhost:11434

# Optional: swap to OpenAI later (not implemented in this version)
# OPENAI_API_KEY=sk-...
